<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chenchen Xu - Home Page</title>
    
    <meta name="author" content="Chenchen Xu">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
    
    <link rel="stylesheet" type="text/css" href="glab.css">
  </head>
  
  <body data-new-gr-c-s-check-loaded="14.1062.0" data-gr-ext-installed="" style="margin: 0;padding: 0;">
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">

              <td style="padding:0%;width:85%;vertical-align:middle">
                <p style="text-align:center">
            <name><strong>Chenchen Xu (许晨晨)</strong></name>
          </p><p>I am a PhD student of the State Key Lab of CAD&CG, Zhejiang University, supervised by Prof. 
              <a href="http://www.cad.zju.edu.cn/home/weiweixu/weiweixu_en.htm">Weiwei Xu</a>. I did my undergrad at Anhui Normal University.
              <br>My research interests are deep learning, layout generation and action recognition. 
              <br><br>
              E-mail: xuchenchen@zju.edu.cn</p>
              </td>
              <td style="padding:2.5%;width:20%;max-width:40%">
                <!-- <img src="images/person.png" width="100px"> -->
                <img src="images/person.png" style="padding-top: 23;padding-bottom: 23;" width=100 height=100 alt=""/>
              </td>

            </tr>
        </tbody></table>

        
          <hr>
          <table style="width:100%;"><tbody>
              <tr>
              <td style="padding-bottom:20px;width:100%;vertical-align:middle">
                <heading>Publications</heading>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;"><tbody>
      
            <tr>
              <!-- <td style="vertical-align:middle;">
                <a href="papers/scalable-nisr/snisr.pdf"><img src="images/snisr.jpg" width=350></a></td> -->

            <!-- <td style="vertical-align:middle;">
                <video width="350px" poster="images/snisr.jpg" muted="muted" onMouseOver="this.play()" onMouseOut="this.pause()" class="video_class"  loop>
                    <source src="videos/t_video.mp4"  type="video/mp4"></source>
                </video>
            </td> -->
            

            <tr>
                <!-- <td style="vertical-align:middle;">
                    <a href="https://superxjm.github.io/source_files/ReflectiveIBR.pdf"><img src="images/sibr.png" width=350></a>
                </td> -->

                <td style="vertical-align:middle;">
                    <div class="video">
                      <img src="images/CVPR2023.png" style="padding-top: 23;padding-bottom: 23;" width=350 height=150 alt=""/>
                        <!-- <div class="img2"  onmouseover="come2()"><img src="images/sibr.png" style="padding-top: 23;padding-bottom: 23;" width=350 height=150 alt=""/></div> -->
                        <!-- <a href="此处填写你想要跳转的地址"> -->
                        <!-- <video id="video2"  style="display: none"  src="videos/445.mp4" width=350 height=196 onmouseout="go2()" loop autoplay playsinline></video> -->
                        <!-- </a> -->
                    </div>
                </td>

                <td style="padding:20px;vertical-align:middle">
                    <a href="https://superxjm.github.io/source_files/ReflectiveIBR.pdf"><papertitle>Unsupervised Domain Adaption with Pixel-level Discriminator for Image-aware Layout Generation</papertitle></a>
                  <br>
                  <a href="https://github.com/ChenchenXu218/ChenchenXu218.github.io/"><u>Chenchen Xu</u></a>, <br>
                  <a href="hhttps://github.com/minzhouGithub/"><u>Min Zhou</u></a>,
                  <a>Tiezheng Ge</a>,
                  <a>Yuning Jiang</a>,
                  <a href="http://www.cad.zju.edu.cn/home/weiweixu/weiweixu_en.htm"><u>Weiwei Xu</u></a>  
                  <br>
                  <h5><strong>CVPR 2023</strong><h5>
                  <a href=""><strong>project</strong></a> |
                  <a href="papers/CVPR2023.pdf"><strong>paper</strong></a> |
                  <a href="videos/CVPR2023.mp4"><strong>video</strong></a> |
                  <p>Layout is essential for graphic design and poster generation. Recently, applying deep learning models to generate layouts has attracted increasing attention. This paper focuses on using the GAN-based model conditioned on
                    image contents to generate advertising poster graphic layouts, which requires an advertising poster layout dataset
                    with paired product images and graphic layouts. However, the paired images and layouts in the existing dataset
                    are collected by inpainting and annotating posters, respectively. There exists a domain gap between inpainted posters
                    (source domain data) and clean product images (target domain data). Therefore, this paper combines unsupervised
                    domain adaption techniques to design a GAN with a novel
                    pixel-level discriminator (PD), called PDA-GAN, to generate graphic layouts according to image contents. The
                    PD is connected to the shallow level feature map and computes the GAN loss for each input-image pixel. Both quantitative and qualitative evaluations demonstrate that PDAGAN can achieve state-of-the-art performances and generate high-quality image-aware graphic layouts for advertising posters.</p>
                </td>
              </tr> 


            <td style="vertical-align:middle;">
            <div class="video2">
              <!-- <img src="images/ijcai2022.png" width=350 height=196 alt=""/> -->
              <img src="images/ijcai2023.png" style="padding-top: 23;padding-bottom: 23;" width=350 height=150 alt=""/>
                <!-- <div class="img"  onmouseover="come()"><img src="images/snisr.jpg" width=350 height=196 alt=""/></div> -->
                <!-- <a href="此处填写你想要跳转的地址"> -->
                <!-- <video id="video" style="display: none"  src="videos/t_video.mp4" width=350 height=196 onmouseout="go()" loop autoplay playsinline></video> -->
                <!-- </a> -->
            </div>
            </td>
    

              <td style="padding-left:20px; vertical-align:middle;">
                <a href="papers/ijcai2022.pdf"><papertitle>Composition-aware Graphic Layout GAN for Visual-textual Presentation Designs</papertitle></a>
                <br>
                <a href="hhttps://github.com/minzhouGithub/"><u>Min Zhou*</u></a>,
                <a href="https://github.com/ChenchenXu218/ChenchenXu218.github.io/"><u>Chenchen Xu*</u></a>, <br>
                <a>Tiezheng Ge</a>,
                <a>Yuning Jiang</a>,
                <a href="http://www.cad.zju.edu.cn/home/weiweixu/weiweixu_en.htm"><u>Weiwei Xu</u></a>
                <br>
          <h5><strong>IJCAI 2022</strong><h5> 
             (* joint first author) <br>
                <a href=""><strong>project</strong></a> |
                <a href="papers/ijcai2022.pdf"><strong>paper</strong></a> |
                <a href="videos/CVPR2023.mp4"><strong>video</strong></a> |
                <p>In this paper, we study the graphic layout generation problem of producing high-quality visualtextual presentation designs for given images. We note that image compositions, which contain not only global semantics but also spatial information, would largely affect layout results. Hence, we propose a deep generative model, dubbed as composition-aware graphic layout GAN (CGLGAN), to synthesize layouts based on the global and spatial visual contents of input images. To obtain training images from images that already contain manually designed graphic layout data, previous work suggests masking design elements (e.g., texts and embellishments) as model inputs, which inevitably leaves hint of the ground truth. We study the misalignment between the training inputs (with hint masks) and test inputs (without masks), and design a novel domain alignment module (DAM) to narrow this gap. For training, we built a large-scale layout dataset which consists of 60,548 advertising posters with annotated layout information. To evaluate the generated layouts, we propose three novel metrics according to aesthetic intuitions. Through both quantitative and qualitative evaluations, we demonstrate that the proposed model can synthesize highquality graphic layouts according to image compositions</p>
              </td>
            </tr> 
      

  
        </tbody></table></table>
        

        <footer class="footer">
            
        </footer>

        


  
  </body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>

<script src="js/temp.js"></script>
<script>
    myVid=document.getElementById("video");
    myVid.muted=true;
    function come() {
        $("#video").show();
        $(".img").hide();
        // $("#video").load();//执行一次加载一次，从头开始播放
        // $("#video").currentTime = 0;
        $("#video")[0].play();
    }
    function go() {
        $(".img").show();
        $("#video").hide();
        $("#video")[0].pause();
        // $("#video").get(0).currentTime = 0;
    }
</script>
<script>
    myVid=document.getElementById("video2");
    myVid.muted=true;
    function come2() {
        $("#video2").show();
        $(".img2").hide();
        // $("#video").load();//执行一次加载一次，从头开始播放
        $("#video2")[0].play();
    }
    function go2() {
        $(".img2").show();
        $("#video2").hide();
        $("#video2")[0].pause();
    }
</script>
